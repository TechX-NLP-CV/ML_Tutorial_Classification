{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Machine Learning Tutorial: Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is Classification?\n",
    "Classification is the problem to correctly predict the class of the given input data. Unlike the regression problem (which could predict a specifict value), the classification aims to tell which category the data belongs to.\n",
    "\n",
    "There are generally 4 types of different classification problems:\n",
    "\n",
    "1. Binary Classification: this could only predict the result from 2 possible classes. For example, you might want to classify an email as **spam** or **not spam** depending on the content.\n",
    "\n",
    "2. Multi-Class Classification: this could predict the result from more than 2 possible classes. For example, you might want to know the type of fruits from **apple**, **pear**, **orange** and so on.\n",
    "\n",
    "3. Multi-Label Classification: this could predict more than 1 labels for each data. For example, within a movie classification task, a movie might be simultaneously belongs to lots of different types of labels like **Action**, **Adventure**, **Fantasy** and you want to get 3 labels for every movie you want to predict.\n",
    "\n",
    "4. Imbalanced Classification: this means that during training process the distribution of examples for each category is not consistent.\n",
    "\n",
    "Within this tutorial, we will explore the binary classification deeply and help you understand more about the supervised learning and the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is Supervised Learning?\n",
    "Supervised learning is the machine learning task to learn a mapping between the input featuers and the output and the goal is to ***generalise from the training data to accurately find the result for unseen data.***\n",
    "\n",
    "Within the classification, we would like to know the relationship between the ***features*** and the ***class label***. In other words, we want to train the model so it could generally classify ***objects with 4 wheels*** as a ***car.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Training, Validation and Test Sets (Very Important!!!) (You could skip this part if you have seen this in other tutorials)\n",
    "As we have seen, the reason why machine learning algorithms could have this fancy performance is that generally they use a very large amount of data to \"learn\" how to solve the problem.\n",
    "\n",
    "Within this \"learning\" process, we could divide data into training, validation adn test datasets for different purpose:\n",
    "\n",
    "1. Training set ***(could \"see\", could \"use\" in the training)***: The model could access to this dataset to optimise the weights and do calculations in the training.\n",
    "\n",
    "2. Validation set ***(could \"see\", can't \"use\" in the training)***: During the training, the model could only use the validation set to determine how good it could perform.\n",
    "\n",
    "3. Test set: ***(can't \"see\", can't \"use\" in the training)***: After training, the model could use the test set to determine how good it could perform on unseen data.\n",
    "\n",
    "The validation set and test set are very similar as they are both used for evaluating the accuracy of the model. However, the key difference is that (very important!!!):\n",
    "\n",
    "1. ***Validation set could be used during the training process, which means you could observe the loss information and tune the hyperparameters but can't use it for optimisation and calculation.***\n",
    "\n",
    "2. ***Test set could only be used after the training is finished. It is used to check how the model could perform on absolutely unseen data. In other words, you can't do any modification to the model once you use the test set.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Linear Classifier (Binary)\n",
    "Let's consider the below graph:\n",
    "\n",
    "1. This is a 2D feature space, which means that each point within this space has 2 features, $x_1$ and $x_2$.\n",
    "\n",
    "2. Within our case, we could simply define $y=sign(\\theta\\cdot x)$, which could output $1$ if the dot product between the model weight $\\theta$ and the input data $x$ is positive. Otherwise it could output $-1$ if the dot product is negative.\n",
    "\n",
    "3. Graphically, the model could be represented as the $\\theta$ vector and we define the ***decision boundary*** as ***the line perpendicular to that vector***. If the input data falls into the purple area (in which the dot product is always greater than 0), it is classified to be ***class A***. The same principle could be applied to the blue area, where points are classified as ***class B***.\n",
    "\n",
    "5. By adjusting the model weight $\\theta$, we are actually changing the gradient of the decision boundary. By allowing the offset $\\theta _0$, we could modify the intercept of the decision boundary.\n",
    "\n",
    "6. If the dot product is 0, which means that the point lies exactly on the decision boundary, we can't give it a valid class.\n",
    "\n",
    "We will come back to the margin boundary later.\n",
    "\n",
    "![Binary Classification](https://miro.medium.com/max/1400/1*sfqR-rZSYaITJ5_PbXU_9w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Classification Error\n",
    "We could use the classification erro to determine how good our classifier could perform.\n",
    "\n",
    "This is simply defined as ***the ratio between the number of wrong predictions and the number of total preditions***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Perceptron Algorithm\n",
    "##### 3.4.1 Matrix Definition\n",
    "Before we dive into the perceptron algorithm, let us express our problem in the matrix form, which could be calculated efficiently.\n",
    "\n",
    "Within the linear classification problem (binary), we have the following components:\n",
    "\n",
    "1. N different labels as a (N,1) matrix Y where each label could only be chosen from {-1, 1}\n",
    "\n",
    "$$\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix}$$\n",
    "\n",
    "2. N different x values with d features as a (N,d+1) matrix $X$\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & x_{1,1} & x{1,2} & \\dots & x_{1,d} \\\\\n",
    "1 & x_{2,1} & x{2,2} & \\dots & x_{2,d} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\dots & \\vdots \\\\\n",
    "1 & x_{N,1} & x{N,2} & \\dots & x_{N,d} \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "3. $\\theta$ as (d+1, 1) matrix\n",
    "\n",
    "$$\\begin{bmatrix} \\theta _0 \\\\ \\theta _1 \\\\ \\vdots \\\\ \\theta _N \\end{bmatrix}$$\n",
    "\n",
    "In this way, we could have $X\\theta =\\theta _0+\\sum_{i=1}^{d} \\theta _ix_i$ and our classifier could output $sign(X\\theta)=sign(\\theta _0+\\sum_{i=1}^{d} \\theta _ix_i)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.2 Detailed Algorithm\n",
    "The whole algorithm contains the following steps:\n",
    "\n",
    "1. Initialise our $\\theta$ as a vector full of 0.\n",
    "\n",
    "2. Use every point in the training set from 1 to N:\n",
    "\n",
    "    a. Check whether the classifier could give a correct prediction for the point i by determing $y_i(\\theta\\cdot x_i)\\leqslant 0$ (If the prediction is inconsistent with the label, their product must be negative)\n",
    "\n",
    "    b. If it is incorrect, update the model by using $\\theta _{new}=\\theta + y_ix_i^T$\n",
    "\n",
    "3. Repeat the step 2 until reaching the maximum number of epoch.\n",
    "\n",
    "It could be seen from the above that this is a very simple algorithm and the core idea is that ***only updating the model awhen it can't give a corret prediction.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.3 Model Update\n",
    "You might wonder why we use $\\theta _{new}=\\theta + y_ix_i^T$ to update the model and whether it is efficient.\n",
    "\n",
    "Before updating, we have $y_i(\\theta\\cdot x_i)$\n",
    "\n",
    "After updating, we have $y_i(\\theta _{new}\\cdot x_i)=y_i[(\\theta + y_ix_i^T)\\cdot x_i]$\n",
    "\n",
    "If we calculate the difference between the updated value and the original value, we could get $y_i[(\\theta + y_ix_i^T)\\cdot x_i]-y_i(\\theta\\cdot x_i)=y_i^2\\lVert x_i \\rVert^2 >0$\n",
    "\n",
    "This means that our updated model could always have a greater chance to pass the check and make the prediction and true label consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.1 Distance between a Point and a Line\n",
    "Before we talk about the margin and the margin boundary, let us revise the equation for calculating the distance between a point and a line.\n",
    "\n",
    "If we have a line $\\theta\\cdot x=0$ and an arbitrary point $x_0$, the distance between them is $\\frac{\\left\\lvert \\theta\\cdot x_0 \\right\\rvert}{\\lVert \\theta \\rVert}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.2 Margin and Margin Boundary\n",
    "Let's check the following graph.\n",
    "\n",
    "You might notice that you could find lots of decision boundary that could perfectly classify those \"+\" and \"-\" points. But is there a best one we could get?\n",
    "\n",
    "Here, we define:\n",
    "\n",
    "1. Support Vector: the point within the class that is the closest to the decision boundary\n",
    "\n",
    "2. Margin: the distance between the support vector and the decision boundary\n",
    "\n",
    "3. Margin Boundary: the straight line that is parallel to the decision boundary and the distance between them is the margin\n",
    "\n",
    "If the margin of a decision boundary is greater, that means it has a greater strength to classfy those points and generally could do better when predicting unseen data.\n",
    "\n",
    "This means that **by introducing the margin and margin boundary, it could improve the generalisation of the classifier so it has a greater potential to perform well on any unseen data.***\n",
    "\n",
    "The margin of a decision boundary is mathematically defined as $d_{sv}=\\frac{y_{sv}\\theta\\cdot x_{sv}}{\\lVert \\theta \\rVert}$ where $x_{sv}$ represents the support vector and $y_{sv}$ represents the corresponding class label.\n",
    "\n",
    "However, our $\\theta$ is highly scalable as we are only interested in the sign of the product. To simplify our calculation, we aim to find the $\\theta$ that could make $y_{sv}\\theta\\cdot x_{sv}=1$.\n",
    "\n",
    "By doing this, our margin could be finally expressed as $d_{sv}=\\frac{1}{\\lVert \\theta \\rVert}$\n",
    "\n",
    "![Binary Classification](https://uk.mathworks.com/discovery/support-vector-machine/_jcr_content/mainParsys/image.adapt.full.medium.jpg/1630399098268.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.3 Hinge Loss and Objective Function\n",
    "After introducing the concept of margin, our objective has changed to ***train a model with a high accuracy while keeping the maximum margin at the same time.***\n",
    "\n",
    "To achieve this goal, we will use a different loss function, hinge loss.\n",
    "\n",
    "The hinge loss is defined as $Hinge(\\gamma _i)=0$ if $\\gamma _i\\geqslant 1$ and $Hinge(\\gamma _i)=1-\\gamma _i$ if $\\gamma _i<1$ where $\\gamma _i=d_{i}/d_{sv}$, the ratio between the distance from point i to the decision boundary and the margin.\n",
    "\n",
    "It would be easier to think about this in 2 directions:\n",
    "\n",
    "1. If a point could be correctly classified and the distance is greater than the margin, we don't update the model.\n",
    "\n",
    "2. If a point exceeds the margin or it couldn't be correctly classified, we update the model depending on its position.\n",
    "\n",
    "By using the definition of the margin, it is obvious that $\\gamma _i=\\frac{y_i\\theta\\cdot x_i}{\\lVert \\theta \\rVert}\\cdot\\lVert \\theta \\rVert=y_i\\theta\\cdot x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.4 Empirical Risk (You could skip this part if you have seen this in other tutorials)\n",
    "Although we could train our model to work well on our training/validation sets, we absolutely have no idea how it could perform on the real unseen data.\n",
    "\n",
    "To tackle this problem, we have to use the principle of empirical risk minimisation here.\n",
    "\n",
    "Empirical risk could estimate how the model might perform on the unseen data using the accuracy on the observed dataset.\n",
    "\n",
    "Empirical risk is mathematically defined as: $R(model)=\\frac{1}{N}\\sum_{i=1}^{N} Loss(y_i , model(x_i))$\n",
    "\n",
    "Within our case, the empirical risk could be represented as $R(\\theta)=\\frac{1}{N}\\sum_{i=1}^{N} Hinge(y_i\\theta\\cdot x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.5 Regularisation (You could skip this part if you have seen this in other tutorials)\n",
    "Regularisation could be considered as a resistance for model to perfectly fit the training data.\n",
    "\n",
    "If our model could perfectly fit the training data (very low training loss), this means that it could also fit the noise within the training set very well and generally can't predict the result for unseen data.\n",
    "\n",
    "By adding the regularisation term, only a very big change could update the model, which makes it more robust and stable.\n",
    "\n",
    "Within this tutorial, we will focus on the L2 Regularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.6 Objective Function\n",
    "Our final objective function is defined as $J_ {\\lambda, N}(\\theta)=R(\\theta)+\\frac{\\lambda}{2} \\lVert \\theta \\rVert_2^2=\\frac{1}{N}\\sum_{i=1}^{N} Hinge(y_i\\theta\\cdot x_i)+\\frac{\\lambda}{2}\\sum_{i=0}^N \\theta _i ^2 $\n",
    "\n",
    "The first term is the average loss term, which could train the model to get a high accuracy.\n",
    "\n",
    "The second term is the regularisation term, which could improve the generalisation of the model and perform well on unseen data.\n",
    "\n",
    "The hyperparameter $\\lambda$ is the regularisation coefficient, which could balance the above effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.7 Gradient Descent: Concept (Very Important!!!) (You could skip this part if you have seen it in other tutorials)\n",
    "Gradient descent is a very efficient and powerful method used during the optimisation in the machine learning algorithm.\n",
    "\n",
    "The goal of optimisation is ***to find the local minimum (global minimum if you are super lucky) of the loss function to get a more accurate model***.\n",
    "\n",
    "Imagine you are on a mountain and you want to go back to the bottom of the mountain. Here is a list of what you might do:\n",
    "\n",
    "1. Find the path pointing downwards, which is the inverse way of the path you climbed up ***(Find the negative of the gradient of the loss function at the certain point).***\n",
    "\n",
    "2. Go down towards the buttom by one step ***(Update the loss by using multiplying the negative gradient and the learning rate).***\n",
    "\n",
    "3. Repeat step 1 and 2 until you reach the buttom ***(For each epoch, find the new gradient and update the loss using that).***\n",
    "\n",
    "We will explain this more in the gradient-based method part later.\n",
    "\n",
    "![Gradient Descent](https://miro.medium.com/max/1400/1*G1v2WBigWmNzoMuKOYQV_g.png \"Gradient Descent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.8 Gradient Descent Based Method\n",
    "We could use gradient descent based method instead as it could save a lot of time while keeping a relatively high accuracy.\n",
    "\n",
    "The gradient descent based method contains the following main steps:\n",
    "\n",
    "1. Initialise our $\\theta$ as a vector full of 0.\n",
    "\n",
    "2. Use every point in the training set from 1 to N:\n",
    "\n",
    "    a. Check the sign of $Hinge(y_i\\theta\\cdot x_i)$\n",
    "\n",
    "    b. Update the model according to the result of step 2(a)\n",
    "\n",
    "3. Repeat the step 2 until reaching the maximum number of epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.9 Detailed Gradient Descent Method Analysis\n",
    "The general equation to optimize the model is: $\\theta=\\theta - rate\\cdot\\nabla _\\theta R(\\theta)$\n",
    "\n",
    "Our objective function is:  $J_ {\\lambda, N}(\\theta)=R(\\theta)+\\frac{\\lambda}{2} \\lVert \\theta \\rVert_2^2=\\frac{1}{N}\\sum_{i=1}^{N} Hinge(y_i\\theta\\cdot x_i)+\\frac{\\lambda}{2}\\sum_{i=0}^N \\theta _i ^2 $\n",
    "\n",
    "Theoretically, we need to use the entire dataset to compute gradient accurately and optimize the model. However, this could be painful if we have lots of data.\n",
    "\n",
    "Alternatively, we could estimate the gradient by calculating the accurate gradient at a specific randomly chosen point, which is known as stochastic gradient descent (SGD).\n",
    "\n",
    "This method could significantly decrease the computational cost and it makes lots of machine learning and deep learning algrotihms powerful.\n",
    "\n",
    "If we use SGD, our objective function is simplified into $Hinge(y_i\\theta\\cdot x_i)+\\frac{\\lambda}{2}\\sum_{i=0}^N \\theta _i ^2 $\n",
    "\n",
    "The first derivative of hinge loss with respect to $\\theta$ is:\n",
    "\n",
    "1. 0 if the hinge loss is less than 0\n",
    "\n",
    "2. $-y_ix_i^T$ if the hinge loss is greater than 0\n",
    "\n",
    "So the first derivate of the simplified objective function with respect to $\\theta$ is: \n",
    "\n",
    "1. $\\lambda\\theta$ if the hinge loss is less than 0\n",
    "\n",
    "2. $\\lambda\\theta - y_ix_i^T$ if the hinge loss is greater than 0\n",
    "\n",
    "Thus, we could update our $\\theta$ according to the hinge loss:\n",
    "\n",
    "1. $\\theta _{new}=\\theta-rate\\cdot\\lambda\\theta$ if the hinge loss is less than 0\n",
    "\n",
    "2. $\\theta _{new}=\\theta-rate\\cdot\\lambda\\theta+ y_ix_i^T$ if the hinge loss is greater than 0\n",
    "\n",
    "The biggest difference between the perceptron algorithm and the SVM algorithm is that ***the SVM algorithm will still update the model even it could correctly classify the current point.***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85f7d4b76af0bdc033882a17c4ab285a68052c0160eb92b69fd8bca0b7c220f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
